{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f62ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found images per class:\n",
      "lycra_cut: 2\n",
      "twoply: 3\n",
      "needln: 5\n",
      "hole: 2\n",
      "non_defect: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting train - lycra_cut: 100%|██████████| 1/1 [00:16<00:00, 16.05s/it]\n",
      "Augmenting train - twoply: 100%|██████████| 2/2 [00:33<00:00, 16.55s/it]\n",
      "Augmenting train - needln: 100%|██████████| 4/4 [01:02<00:00, 15.74s/it]\n",
      "Augmenting train - hole: 100%|██████████| 1/1 [00:15<00:00, 15.14s/it]\n",
      "Augmenting train - non_defect: 100%|██████████| 40/40 [06:13<00:00,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Augmentation complete. Output at: augmented_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------\n",
    "# Config\n",
    "# ------------------\n",
    "RAW_DATA_DIR = \"raw_data\"      # Root folder containing all class subfolders\n",
    "OUTPUT_DIR = \"augmented_data\"  # Augmented dataset output folder\n",
    "\n",
    "TARGET_TOTAL = 12000\n",
    "TRAIN_TARGET = 10000\n",
    "VAL_TARGET = 2000\n",
    "\n",
    "VAL_ORIGINALS = {\n",
    "    \"non_defect\": 10,\n",
    "    \"hole\": 1,\n",
    "    \"lycra_cut\": 1,\n",
    "    \"needln\": 1,\n",
    "    \"twoply\": 1\n",
    "}\n",
    "\n",
    "PER_ORIGINAL_COUNTS = {\n",
    "    \"non_defect\": 120,\n",
    "    \"hole\": 200,\n",
    "    \"lycra_cut\": 200,\n",
    "    \"needln\": 200,\n",
    "    \"twoply\": 200\n",
    "}\n",
    "\n",
    "PROBS = {\n",
    "    \"hflip\": 0.5,\n",
    "    \"vflip\": 0.3,\n",
    "    \"rotate180\": 0.4,    # probability of rotating exactly 180 degrees\n",
    "    \"brightness\": 0.4,\n",
    "    \"contrast\": 0.4,\n",
    "    \"sharpness\": 0.3,\n",
    "    \"blur\": 0.2,\n",
    "    \"zoom\": 0.4       # probability of zooming in only\n",
    "}\n",
    "\n",
    "# ------------------\n",
    "# Helper functions\n",
    "# ------------------\n",
    "def collect_images(root=RAW_DATA_DIR):\n",
    "    classes = {}\n",
    "    for root_dir, dirs, files in os.walk(root):\n",
    "        if root_dir == root:\n",
    "            continue\n",
    "        cls_name = os.path.basename(root_dir)\n",
    "        image_files = [\n",
    "            os.path.join(root_dir, f)\n",
    "            for f in files\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ]\n",
    "        if image_files:\n",
    "            classes[cls_name] = image_files\n",
    "    return classes\n",
    "\n",
    "\n",
    "def split_originals(classes):\n",
    "    train_split = {}\n",
    "    val_split = {}\n",
    "    for cls, images in classes.items():\n",
    "        random.shuffle(images)\n",
    "        val_count = VAL_ORIGINALS.get(cls, 0)\n",
    "        val_split[cls] = images[:val_count]\n",
    "        train_split[cls] = images[val_count:]\n",
    "    return train_split, val_split\n",
    "\n",
    "\n",
    "def pad_to_square(image, fill_color=(0, 0, 0)):\n",
    "    w, h = image.size\n",
    "    if w == h:\n",
    "        return image\n",
    "    max_side = max(w, h)\n",
    "    delta_w = max_side - w\n",
    "    delta_h = max_side - h\n",
    "    padding = (delta_w // 2, delta_h // 2,\n",
    "               delta_w - delta_w // 2, delta_h - delta_h // 2)\n",
    "    return ImageOps.expand(image, padding, fill=fill_color)\n",
    "\n",
    "\n",
    "def zoom_out(image, scale=0.8, fill_color=(0, 0, 0)):\n",
    "    \"\"\"Zoom out by scaling down and padding to original size.\"\"\"\n",
    "    w, h = image.size\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    image_resized = image.resize((new_w, new_h), Image.LANCZOS)\n",
    "\n",
    "    background = Image.new(\"RGB\", (w, h), fill_color)\n",
    "    offset = ((w - new_w) // 2, (h - new_h) // 2)\n",
    "    background.paste(image_resized, offset)\n",
    "    return background\n",
    "\n",
    "\n",
    "def augment_image(image):\n",
    "    if random.random() < PROBS[\"hflip\"]:\n",
    "        image = ImageOps.mirror(image)\n",
    "    if random.random() < PROBS[\"vflip\"]:\n",
    "        image = ImageOps.flip(image)\n",
    "    if random.random() < PROBS[\"rotate180\"]:\n",
    "        image = image.rotate(180, expand=True)\n",
    "    if random.random() < PROBS[\"brightness\"]:\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        image = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    if random.random() < PROBS[\"contrast\"]:\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        image = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    if random.random() < PROBS[\"sharpness\"]:\n",
    "        enhancer = ImageEnhance.Sharpness(image)\n",
    "        image = enhancer.enhance(random.uniform(0.8, 1.5))\n",
    "    if random.random() < PROBS[\"blur\"]:\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n",
    "    if random.random() < PROBS[\"zoom\"]:\n",
    "        image = zoom_out(image, scale=random.uniform(1.1, 1.3))\n",
    "    return image\n",
    "\n",
    "\n",
    "def save_augmented(images, cls, split, count_per_original):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, split, cls)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for img_path in tqdm(images, desc=f\"Augmenting {split} - {cls}\"):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        for _ in range(count_per_original):\n",
    "            aug_img = augment_image(img)\n",
    "            aug_img = pad_to_square(aug_img)\n",
    "            aug_img.save(os.path.join(save_dir, f\"{cls}_{idx}.png\"))\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def copy_originals(images, cls, split):\n",
    "    save_dir = os.path.join(OUTPUT_DIR, split, cls)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for img_path in images:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = pad_to_square(img)\n",
    "        img.save(os.path.join(save_dir, os.path.basename(img_path)))\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Main\n",
    "# ------------------\n",
    "def main():\n",
    "    random.seed(42)\n",
    "\n",
    "    classes = collect_images(RAW_DATA_DIR)\n",
    "    print(\"\\nFound images per class:\")\n",
    "    for cls, imgs in classes.items():\n",
    "        print(f\"{cls}: {len(imgs)}\")\n",
    "\n",
    "    train_split, val_split = split_originals(classes)\n",
    "\n",
    "    for cls, images in train_split.items():\n",
    "        count_per_original = PER_ORIGINAL_COUNTS.get(cls, 1)\n",
    "        save_augmented(images, cls, \"train\", count_per_original)\n",
    "\n",
    "    for cls, images in val_split.items():\n",
    "        copy_originals(images, cls, \"val\")\n",
    "\n",
    "    print(\"\\n✅ Augmentation complete. Output at:\", OUTPUT_DIR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd39c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
